<?xml version="1.0" encoding="utf-8"?>
<databaseChangeLog
        xmlns="http://www.liquibase.org/xml/ns/dbchangelog"
        xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
        xsi:schemaLocation="http://www.liquibase.org/xml/ns/dbchangelog http://www.liquibase.org/xml/ns/dbchangelog/dbchangelog-3.5.xsd">

    <changeSet id="20240403001" author="Manuel">

        <sql dbms="postgresql" splitStatements="true" stripComments="true">
            <![CDATA[
                INSERT INTO utm_logstash_filter (id, logstash_filter, filter_name, filter_group_id, system_owner, module_name, is_active, filter_version)
                VALUES (1523, 'filter {

#Netflow filter bassed on https://www.cisco.com/en/US/technologies/tk648/tk362/technologies_white_paper09186a00800a3db9.html (february 2022)
#and http://www.iana.org/assignments/ipfix/ipfix.xhtml (february 2022)

#Filter version 2.0.1
   split {
     field => "message"
     terminator => "<utm-log-separator>"
   }

   #Looking for datasource generated by an agent and parse original message
   if [message]=~/\[utm_stack_agent_ds=(.+)\]-(.+)/ {
     grok {
       match => {
         "message" => [ "\[utm_stack_agent_ds=%{DATA:dataSource}\]-%{GREEDYDATA:original_log_message}" ]
       }
     }
   }
   if [original_log_message] {
     mutate {
       update => { "message" => "%{[original_log_message]}" }
     }
   }

   json {
     source => "message"
   }

   if [netflow]{
#......................................................................#
#Generating dataSource field required by CurrelationRulesEngine
#Checks if exists, if not evaluate to the host variable
   if (![dataSource]){
      mutate {
        add_field => { "dataSource" => "%{host}" }
      }
   }
#......................................................................#
#Generating dataType field required by CurrelationRulesEngine
      mutate {
        add_field => { "dataType" => "netflow" }
      }
#......................................................................#
#Generating fields required by correlation rules
      mutate {
        #Netflows v9 fields
        rename => {"[netflow][l4_src_port]" => "[logx][netflow][src_port]"}
        rename => {"[netflow][ipv4_src_addr]" => "[logx][netflow][src_ip]"}
        rename => {"[netflow][l4_dst_port]" => "[logx][netflow][dest_port]"}
        rename => {"[netflow][ipv4_dst_addr]" => "[logx][netflow][dest_ip]"}
        rename => {"[netflow][protocol]" => "[logx][netflow][proto]"}

        #IPFIX fields
        rename => {"[netflow][sourceTransportPort]" => "[logx][netflow][src_port]"}
        rename => {"[netflow][sourceIPv4Address]" => "[logx][netflow][src_ip]"}
        rename => {"[netflow][destinationTransportPort]" => "[logx][netflow][dest_port]"}
        rename => {"[netflow][destinationIPv4Address]" => "[logx][netflow][dest_ip]"}
        rename => {"[netflow][protocolIdentifier]" => "[logx][netflow][proto]"}
      }
#......................................................................#
#Generating logx tree structure
      mutate {
        #Netflows fields
        rename => {"[netflow]" => "[logx][netflow]"}
      }
#......................................................................#
#Finally, remove unnecessary fields
   mutate {
      remove_field => ["@version","path"]
   }
}
   #Also, remove unwanted fields if the message not match with conditions
   mutate {
      remove_field => ["original_log_message","headers"]
   }
}', 'netflow', null, true, 'NETFLOW', false, '2.0.1');
            ]]>
        </sql>
        <sql dbms="postgresql" splitStatements="true" stripComments="true">
            <![CDATA[
                    INSERT INTO utm_logstash_pipeline (id, pipeline_id, pipeline_name, parent_pipeline, pipeline_status, module_name, system_owner, pipeline_description, pipeline_internal, events_in, events_filtered, events_out, reloads_successes, reloads_failures, reloads_last_failure_timestamp, reloads_last_error, reloads_last_success_timestamp)
                    VALUES (48, 'netflow', 'Netflow', null, 'up', 'NETFLOW', true, null, false, 0, 0, 0, 0, 0, null, null, null);

                    INSERT INTO utm_group_logstash_pipeline_filters (filter_id, pipeline_id, relation)
                    VALUES (1523, 48, 'PIPELINE_FILTER');

                    INSERT INTO utm_logstash_input (id, pipeline_id, input_pretty_name, input_plugin, input_with_ssl, system_owner)
                    VALUES (64, 48, 'HTTP', 'http', false, true);

                    INSERT INTO utm_logstash_input_configuration (input_id, conf_key, conf_value, conf_type, conf_required, conf_validation_regex, system_owner)
                    VALUES (64, 'http_port', '10044', 'port', true, '^((6553[0-5])|(655[0-2][0-9])|(65[0-4][0-9]{2})|(6[0-4][0-9]{3})|([1-5][0-9]{4})|([0-5]{0,5})|([0-9]{1,4}))$', true);

                    INSERT INTO utm_index_pattern (id, pattern, pattern_module, pattern_system, is_active)
                    VALUES (64,'log-netflow-*', 'NETFLOW', true, true);

                    INSERT INTO utm_data_source_config (data_type, data_type_name, system_owner, included)
                    VALUES ( 'netflow', 'Netflow', true, true);

                    INSERT INTO utm_menu (id, name, url, parent_id, type, dashboard_id, position, menu_active, menu_action, menu_icon, module_name_short)
                    VALUES (262, 'Netflow', 'discover/log-analyzer?patternId=64&indexPattern=log-netflow-*', 200, 1, null, 61, false, false, null, 'NETFLOW');

                    INSERT INTO utm_menu_authority (menu_id, authority_name)
                    VALUES ( 262, 'ROLE_USER');

                    INSERT INTO utm_menu_authority (menu_id, authority_name)
                    VALUES ( 262, 'ROLE_ADMIN');


            ]]>


        </sql>
    </changeSet>
</databaseChangeLog>
